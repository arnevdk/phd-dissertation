\chapter{Conclusion \& recommendations}
\epigraph{``The mystery of life isn't a problem to solve, but a reality to
experience.''}{ Reverend Mother Gaius Helen Mohiam in \\ \emph{Dune -- Frank
Herbert}\\ adapted from S{\o}ren Kierkegaard}
\noindent\emph{The first paragraph of \cref{sec:conclusion/contrib/decoders} was published as
part of \textcite{VanDenKerchove2022}.}


\section{Contributions}

This work aimed to improve the performance of visual gaze-independent \acsp{bci}, in general
and when applied to individuals with eye motor impairment, by developing novel decoding
strategies and evaluating their effectiveness.
We addressed the limitations of current gaze-dependent \acp{bci} by proposing methods that
exploit covert \ac{vsa} and reduce the reliance on eye gaze.
The following key contributions were made:

\subsection{Developed \acs{erp} decoders}
\label{sec:conclusion/contrib/decoders}
We introduced a covariance estimator using adaptive shrinkage (STBF-shrunk) and an estimator
exploiting prior knowledge about the spatiotemporal nature of the EEG signal
(STBF-struct).
We compared these estimators with the original formulation of the
spatiotemporal (STBF-emp)
beamformer and a state-of-the-art Riemannian Geometry method (XDAWN+RG) in an off-line P3 detection task on
an existing dataset.
Our results show that the structured estimator results in an accuracy
increase of up to 4 \%. compared to shrinkage regularization.
y when training data are sparsely available.
Results can be computed faster and with
substantially less memory usage.
Since these algorithms are not paradigm-specific, the conclusions can be
generalized to other ERP-based BCI settings.
These results have been published in~\textcite{VanDenKerchove2022}.

Next, \acf{bttda} was introduced as a tensor-based decoder that better captures the
multidimensional nature of \ac{erp} data.
By preserving the structure of neural data, \ac{bttda} can cope with noise and other challenges
arising from gaze-independent \acp{bci}, yielding robust results under certain conditions.
Results show that \ac{bttda} and its special sum-of-rank-one structured case
improved over \ac{hoda} and can reach state-of-the-art decoding performance for
\acp{erp}.
This work is submitted as~\textcite{VanDenKerchove2024a}.

Finally, we developed the \acf{wcble} decoder, specifically designed to address
the challenges posed by P3 latency jitter in covert \ac{vsa} settings.
Latency variability is a well-known issue in \ac{erp} decoding, particularly
when users engage in covert attention, where the timing of the P3 component
fluctuates significantly across trials.
Traditional decoders struggle in these settings due to the inconsistent timing
of brain responses, which can reduce the robustness and accuracy of
\ac{erp} decoding.
The \ac{wcble} decoder mitigates this issue by introducing an iterative process
to estimate and align \ac{erp} latencies across trials.
This is performed in such a way that discriminative power of the \ac{erp}
signal is preserved and enhanced.
The method has been published in~\textcite{VanDenKerchove2024}.
We designed this method to improve decoding where
unseen incoming test data is not yet known.
\Ac{wcble} was first tested on synthetic data to evaluate its
effectiveness under conditions of controlled latency variability and noise.
These results showed that it is robust to higher noise and jitter\ compared to
a non-iterative method in a latency estimation task.
Decoding accuracy was higher in high jitter and noise
settings compared to the non-iterative method and a state-of-the-art
decoder.

\subsection{Gathered datasets}
The CVSA-ERP dataset consists of recordings of 15 healthy participants, mean age
$26.38\pm3.15$ years.
The dataset was presented in~\textcite{VanDenKerchove2024}.
The experiment in this dataset implemented a visual oddball \ac{bci} with six
circular targets in a hexagonal layout.
The gaze fixation of participants was carefully controlled to dissociate the
visuospatial attention of the participant and their eye gaze.
This allowed us to study the effects of gaze-independence on \ac{erp} decoding.
The CVSA-ERP dataset gives us insight into the ERP dynamics in overt, covert, and the
novel split VSA condition, and confirms our hypothesis that P3 jitter has a
significant impact on performance in covert and split VSA.
It also confirmed that the effects of covert \ac{vsa} on \ac{erp} component
amplitude hold for split \ac{vsa}.

Additionally, we gathered data from 7 individuals with \ac{sspgi} with conditions such as
\ac{als},\ac{fa}, and stroke.
These participants exhibited varying degrees of eye motor impairment, such as
involuntary eye movements, ophthalmoplegia, and gaze fixation fatigue.
The data provide invaluable real-world evidence on how gaze-independent
\acp{bci} perform in populations that experience eye motor difficulties.
This dataset allowed us to evaluate the proposed decoding strategies in clinical settings and
highlighted the practical challenges of implementing gaze-independent \acp{bci} in these user
groups.

\subsection{Investigated gaze-independent visual \acsp{bci}}

We evaluated our proposed \ac{wcble} algorithm, its non-iterative
counterpart, and state-of-the-art decoders on the CVSA-ERP dataset as well as on a publicly available
dataset~\cite{Aloise2012} that also contains the overt and covert VSA conditions.
We evaluated the BCI decoding performance in a single-trial classification experiment,
as well as in a target selection experiment reflecting BCI operation.
Performance was significantly different between decoders, but this
result was significantly dependent on the \ac{vsa} condition and the dataset.
While \ac{wcble} was slightly outperformed by the state-of-the-art in overt \ac{vsa}
decoding ($94.28<94.74$ and  $85.25<86.60$ \% \ac{rocauc}),
it increased covert \ac{vsa} decoding ($80.84>78.90$ and $73.38>71.11$ \%
\ac{rocauc}).

For the split attention conditions in the CVSA-ERP
dataset, \ac{wcble} yielded a significant improvement over CBLE and the
state-of-the-art method only in some cases.
These results were corroborated by analyzing selection accuracy, which showed
similar behavior for both datasets, except in overt
VSA, where accuracy was not harmed by the lower
single-trial selection performance of \ac{wcble}.

To further study the gaze-independent performance of these algorithms, transfer
learning between \ac{vsa} conditions was studied to simulate conditions where an
individual with gaze impairment can end up in different \ac{vsa} settings within
a \ac{bci} operation session due to their lack of proper motor control.
When trained and evaluated on overt VSA data, our proposed \ac{wcble} algorithm
results in a small but significant decrease in performance compared to the state-of-the-art
($85.25>86.60$ and $94.74>94.28$ \% \ac{rocauc}), consistent with the within-condition
results.
For all other pairs of training and evaluation VSA conditions, however,
\ac{wcble} was equal to or significantly better with increases exceeding 4 \%
\ac{rocauc}.

Later case studies explored gaze-independent
\ac{bci} performance in individuals with \ac{sspi} and varying eye motor impairments.
Participants showed different levels of gaze control, with some using overt
\ac{vsa}, while others preferred covert \ac{vsa}, resting their gaze and
mentally attending to targets.

The \ac{wcble} decoder improved decoding accuracy in covert
\ac{vsa} settings with cued central gaze fixation.
This is of interest for gaze-independent decoding, but not as optimal as when the
gaze fixation was uncued.
The latter was tested in the free \ac{vsa} setting.
Here, participants were generally more comfortable when allowed to use their
preferred gaze strategy.
Decoding performance in free \ac{vsa} was often comparable to overt \ac{vsa},
showing the system's flexibility.

Revisiting the hypotheses put forward in
\cref{sec:gaze-independence/objectives}, we conclude that we have proposed
several techniques that did in effect improve visual oddball \ac{erp}-based
\ac{bci} decoding accuracy, and at least one technique that does so specifically
under conditions relevant for gaze-indepent \ac{bci}.
It was not conclusively proven, however, that these results have a meaningful
impact on on-line \ac{bci} assistive technology use by individuals with
\ac{sspgi}.

Together, the obtained results do show that there is an interest in developing
a new class of \ac{erp}-\ac{bci} interfaces for users that prefer to choose their own gaze strategy, to
avoid the effort of redirecting their eye gaze to different spatial locations
on the stimulation screen in manners that might be uncomfortable for them.

\section{Current \& future work}
On the decoder development side, we have partially implemented some interesting
extensions of the proposed methods.
The Kronecker-structured beamformer can be generalized to the \ac{lda} case.
Furthermore, we obtained promising results when extending the single
Kronecker product covariance model to a sum of Kronecker product terms, since
the \ac{eeg} covariance is probably better expressed by such a
structure~\cite{Bijma2005}.
The Kronecker-\ac{lda} approach has also been extended to the combined
space-time-frequency domain, where more information can be modeled at the cost
of increased dimensionality.
A properly structured covariance model can strongly regularize the problem.

To overcome the limitations introduced by the presence of multiple \ac{erp}
components in latency estimation, we have also developed a multi-component
version of the \ac{wcble} algorithm.
This algorithm should be able to separate mixed \ac{erp} component clusters
based on their temporal coherence, in a similar manner to~\textcite{Ouyang2017}.
It could also yield favorable decoding results in a broader range of settings
than overt \ac{vsa}, since it should be able to account for the presence of both
visual and attentional \ac{erp} components.

In gaze-independence decoding, our current efforts focus on --
counterintuitively -- integrating eye tracking into the decoding strategy.
Since we are able to explicitly discern overt, covert, and split \ac{vsa} from
the \ac{erp}, and different decoders perform best in different settings, it
could be helpful to derive the current setting from the gaze position and the
\ac{erp}, and propose the most suited decoder for a given data point.
This could allow us to select the best classifier using eye tracking.

Coincidentally, advances in gaze-independent decoding also build towards a
solution for the Midas Touch Problem in visual \ac{bci}.
Here, a \ac{bci} user sometimes accidentally selects a target while not intending
to give any input.
Decoding of true intention independent of eye
gaze, with the option of gazing without paying visuospatial attention to a
stimulus, would counteract this, and be a valuable addition to a \ac{bci}
assistive technology device.

We also aim to apply the tensor approach to gaze-independent decoding.
The problems introduced by jitter could be accounted for, as in \ac{wcble}, by
alignment, but also by other methods that model the possible time shifts.
In ordering the data as a Hankel tensor\footnote{Adding an extra mode with
time-shifted copies of the temporal response per channel.}, we should have a
data representation that is more robust to jitter, at the cost of increased
dimensionality.
This increased dimensionality can then be countered by a tensor method like
\ac{hoda} or \ac{bttda}.

Finally, we wish to expand our experimentation with individuals with
\ac{sspgi}.
As the work presented in this thesis started during the COVID-19 pandemic,
experimentation was delayed and the envisioned application could not be
validated within the time frame of the doctoral project.
To complete this work, we aim to revisit the participants with an on-line
experiment and satisfaction assessment to establish the usability of the proposed
interface according to the principles of \ac{ucd} and
compare its \ac{itr} to the state-of-the-art literature.

\section{Limitations and recommendations}

\subsection{Decoding: keep it linear; structure it}

Throughout this thesis, we noticed that linear or multilinear decoding
methods consistently outperform non-linear methods, such as SVMs or those based
on Riemannian Geometry.
Within these linear models, regularization (shrinkage, covariance structure,
tensor structure/rank) is of paramount importance, since neural data is
inherently multivariate and \ac{bci} calibration time is minimized.
Proper regularization should impose some specific structure on the linear model,
ideally reflecting properties of the signal.
When faced with a new problem and few data relative to dimensionality, it is a
good first instinct to pick a simple, restrictive structure.

However, the brain is a complex organ, so neural data is not linear in origin.
These regularizing assumptions based on prior knowledge are likely only
superficially true.
When optimizing for performance, it will soon become clear that, given a more
flexible model, there are
settings where these assumptions can be broken to better describe the ongoing
interactions.
For example, spatiotemporal beamforming or \ac{lda} with Kronecker-structured covariance
improves performance in low sample sizes but is outperformed by more flexible
methods, such as \ac{lda} using a Kronecker-sum covariance model or \ac{tlda}
when the training sample size increases.
Similarly, \ac{bttda} offers more flexibility.

This calls for the development of more flexible (multi-)linear models that still rely on some
structure but are combined with efficient model
selection, such as those proposed by \ac{bttda}.
These models try to combine the best of both worlds.

\subsection{Optimize user experience}
While our work with \ac{bci} users with \ac{sspgi} resulted in interesting
preliminary findings, it is currently impossible to make claims about the
experience in long-term home use of the proposed systems as assistive technology.
This work focused heavily on classification methods and solving problems
arising from gaze-independence through decoding.
Since these decoders were evaluated by collecting data and performing tests
later using cross-validation, only off-line performances have been reported.

To gain proper insight in the performance of a system that actually supports
end-users, performance in an on-line experiment should be reported.
The interface, now a collection of white circles, should be adapted
to include meaningful selection elements, like groups of letters or icons and
selection feedback should immediately be presented to the user.
The performance metric then also captures effects of user engagement,
learning and strategy adaptation.
The measured brain activity and the proper execution of the task by the
participant are, after all, partially dependent on their sense of completing a task
that is tangible, entertaining and directly useful for them.
The participant then becomes an active \ac{bci} assistive technology user,
instead of just a near-passive observer in an abstract data collection experiment.

Furthermore, classification performance is only one aspect of what makes a \ac{bci}
desirable as assistive technology.
An interesting approach here is to consider the problem from a
\ac{ucd}~\cite{Standardization2009} perspective.
\Ac{ucd} is a framework for effective optimization and evaluation of usability
in product design, which has successfully been applied to \ac{bci}
development~\cite{Schreuder2013,Kuebler2014,Han2022}.
\Acp{bci} as assistive technologies for users with particular and individual
physical and psychological requirements form a perfect use case for such a framework.

One of the main principles of \ac{ucd} is to address the \emph{entire} user
experience.
As mentioned before, this includes measuring \emph{effectiveness}, in the form
of e.g. selection accuracy.
\Ac{ucd} goes beyond this by also assessing \emph{efficiency} and user
\emph{satisfaction}
Similarly to effectiveness, efficiency can objectively be measured as \ac{itr}
in on-line operation is a better metric.
Satisfaction, on the other hand, is a more subjective quality.

Nevertheless, optimizing user satisfaction is the penultimate goal in
application design.
Satisfaction depends on factors such as performance (in the form of efficiency
and effectiveness), comfort, and user perception.
It must be assessed through subjective questionnaires following realistic, on-line
application use\cite{Kuebler2014}.
Only focusing on evaluating effectiveness through classification performance is
a pragmatic approach, because a researcher can perform a single
data collection and iterate on the results offline.
Yet, this can be too limiting when seeking to design the most usable interface
for a specific group of users.

The optimal approach should unify decoder development, paradigm choice, and interface
design, as advocated by~\textcite{Pan2022} and~\textcite{Fouad2020}, by integrating both
engineering and clinical perspectives.
Performance and abilities likely depend to a great degree on the user,
so off-line decoding performance in healthy controls is probably not a good
predictor of on-line decoding performance and \ac{itr} in individuals with
\ac{sspi}.
Incremental gains in decoding performance for a specific paradigm might
also be outweighed by how well that paradigm is adapted to the user, factoring in
their skills and abilities.
Longitudinal research should follow several user groups, specifically those with gaze
impairment, and experiment with specific paradigms, interfaces, and decoders for
a given \ac{bci} user.

\subsection{Work \emph{with} individuals with \acs{sspi}}

A logical point arising from this is the question of how to set up an
effective research project that aims to optimize \ac{bci} user experience, in
the context of the topics presented in this work.
The patient-research involvement framework postulates that, ideally, individuals with
\ac{sspi} should be involved at every stage of the research project, from conceptualization
to evaluation.
A good rule of thumb is that research should solve problems \emph{with} the
users, not \emph{for} them, implying that research projects should start from
the needs of the \ac{bci} user population.

Instead of choosing a research target and then moving on to decoder
development, data collection with healthy controls, patient studies, and
finally, verification in on-line operation, it could be more effective to start
the other way around.
In a mature field like visual oddball \ac{bci}, the research project can, after
a thorough literature review, immediately start with on-line experimentation
involving individuals with \ac{sspgi} and an adequately chosen, existing \ac{bci} system.
It should then become apparent where challenges for the envisioned user
population lie.
As an example, \textcite{FriedOken2020} share an overview of their experiences from this step,
specifically concerning eye motor impairment in visual \ac{bci}.
After that, hypotheses can be formed on how to mitigate these challenges
through interface optimization or choice, taking into account the full picture
of the capabilities and skills of the users.
These hypotheses can then be verified in experiments
with the users and/or a population of healthy controls.
Finally, the decoder can be optimized, only if it is strongly suspected that
effects will hold in on-line operation.

This approach is tied to another valuable \ac{ucd} principle: encouraging early and active
involvement of users.
Unfortunately, it also might one of the least practical ways to set up
a 4-year research project, such as in the context of a doctoral thesis.
This approach can only work if the proper facilities can be gathered immediately
from the start, such as ethical approval, access to patients, and on-line \acp{bci}
experimentation systems.
It is therefore important that research labs maintain a long-term working
collaboration with patient centers, so that new projects can immediately be
verified with the user population. This also allows interested users to compare
multiple systems and guide development.
The fact that a user has previous \ac{bci} experience is often seen as a confounding
factor in off-line studies.
When the research is in a phase that heavily depends on user
experimentation, this is actually a strength, since the user can help the researcher gain
insight into what works and what does not work for them, and where research efforts
should be focused.

Similarly, there is value in maintaining a working, on-line, in-house \ac{bci}
system that can be iterated upon and adapted if necessary.
Given this system's design and data gathered from earlier use, experiments can
be supported by advance calculations of hypothetical
\ac{itr}, ensuring that on-line or off-line experiments reasonably reflect
real-world operation, and no effort is wasted exploring settings that will not
achieve satisfactory performance.
For example, why study a specific number of repetitions or \ac{isi}, if they
would not be practical to achieve a high \ac{itr}, but could still influence
decoding performance?
Having access to (or implementing) a working, on-line \ac{bci} prototype early
on allows for the implementation of the full \ac{ucd} framework throughout the research
project.
It opens the door for iterative design with interaction between developers and
end-users, yet another \ac{ucd} principle.

This top-down or iterative approach is probably not suited for all types of \ac{bci}
research
If a novel \ac{bci} paradigm is still in an early phase, the focus
should lie on creating limited, fundamental experiments to develop a method to
decode the brain activity of interest and working bottom-up from there to a
proof of concept of an end-user application.
Yet, in visual oddball \ac{bci}, the challenge no longer lies in generating
this proof of concept but in translating it into usable technology.
Here, the top-down approach might help to avoid prematurely solving problems
which may not necessarily arise further down the road.
\Ac{ucd} could improve the quality of study outcomes by enabling the
reporting of realistic, interpretable metrics, and by taking into account the
human aspect of working \emph{with} instead of \emph{for} \ac{bci} users.
