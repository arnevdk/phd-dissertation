\chapter{Kronecker-structured linear decoding}
\label{sec:stbf-struct}
\newcommand{\pv}[1]{
	%\ifdim#1pt<0.05pt
	%	\cellcolor{black!20}
	%\fi
	%\ifdim#1pt<0.001pt
	%	$< 0.001$
	%\else
	%	\ifdim#1pt=1.000pt
	%		\multicolumn{1}{c}{--}
	%	\else
	%		$#1$
	%	\fi
	%\fi
	#1
}
% Kronecker-structured LDA ====================================================

  \emph{This chapter was
  published as~\textcite{VanDenKerchove2022}.}

	\section{Introduction}

	%Brain-computer interfaces (\acp{bci}) establish a direct communication pathway
	%between the brain and an external device~\cite{Wolpaw2002}.
	%Severely disabled patients with impaired or absent communication capabilities
	%can benefit from \acp{bci} to restore normal functioning~\cite{Naci2012,Chaudhary2016}.
	%\acp{bci} can be implemented in multiple ways, using non-invasive recording
	%techniques such as electroencephalography (\ac{eeg})~\cite{Abiri2019},
	%magnetoencephalography (MEG)~\cite{Mellinger2007},
	%functional Near-Infrared Spectroscopy (fNIRS)~\cite{Hong2015}, and Optically Pumped
	%Magnetometers (OPM MEG)~\cite{Paek2020}, or semi-invasive and invasive methods such as
	%electrocorticography (ECoG)~\cite{Schalk2011} or microelectrode
	%arrays~\cite{Maynard1997} which require surgery to implant a recording device.
	%While invasive \acp{bci} yield the highest information transfer
	%rate~\cite{Willett2021}, non-invasive \acp{bci} are preferable for short-term use
	%since they are not susceptible to the risks that come with surgery.
	%Of the non-invasive options, \ac{eeg} is the most cost-effective and practical as it
	%is not limited to the same controlled settings as MEG and OPM MEG.

	%Besides the recording method, \acp{bci} differ in the communication paradigms used
	%for communication~\cite{Abiri2019}.
	%A popular class of \ac{bci} paradigms relies on the evocation
	%of Event-Related Potentials (\acp{erp}) in the brain in response to visual, auditory, or tactile stimulation, given their low decoding cost and generally short
	%calibration time before usage~\cite{Gao2014, Kapgate2015}.
	%The study we report on focuses on the visual P3 oddball \ac{erp} in response to a
	%rare but attended visual stimulus.
	%The decoder detects whether this \ac{erp} is present to determine which stimulus
	%the user attended.
	%The P3 paradigm has been used extensively in \ac{bci} development and is easy to
	%set up~\cite{Farwell1988, Sellers2006, Barachant2014, Philip2020}.

  There are multiple state-of-the-art P3 classification methods, like
  \acp{svm}~\cite{Tayeb2014}, deep
	learning models~\cite{Vareka2020,Borra2020}, and Riemannian Geometry
	classifiers~\cite{Barachant2014}.
	While these models often return a high classification accuracy, there is a need
	for lightweight models -- lightweight models lead to fast off-line analyses and can be transferred to consumer-grade hardware.
	When moving towards plug-and-play solutions, \ac{bci} calibration sessions should be short and model training times low.
  The \ac{stbf}~\cite{VanVliet2015, Wittevrongel2016} belongs to
	this class of \ac{erp} decoding models as it achieves state-of-the-art performance and is fast to train.
	Earlier work has shown that it is
	possible to apply the spatiotemporal beamformer to multiple time-locked visual
  \ac{bci} paradigms, including the P3 oddball paradigm, \ac{ssvep},
  \ac{cvep}~\cite{Wittevrongel2017a}, and the \ac{mvep}~\cite{Libert2021}.

	This work shows that the original spatiotemporal
	beamformer~\cite{Wittevrongel2016} can fall short in performance when \ac{bci}
	calibration data are restricted.
	We also show that the spatiotemporal beamformer does not scale well for
	higher spatial and temporal resolution cases.
	As a response to these issues, we introduce a regularization method that
	exploits prior knowledge about the spatiotemporal nature of the \ac{eeg} signal to
	improve the accuracy for low data availability settings and speed up the
	classifier training time, thereby considerably reducing memory usage.
	Similarly structured regularization approaches have been applied to other linear
	\ac{erp} classifiers~\cite{GonzalezNavarro2017, Vliet2020} and have shown
	significant increases in performance.
%	Additionally, we show that regularization results in an interpretable
%	classification model, which can aid in analyzing and developing spatiotemporal beamformer-based classifiers.

	\section{Materials \& methods}
	\subsection{Notation}
	We represent matrices with bold capital letters, vectors with bold
	lowercase letters, fixed scalars with uppercase cursive letters and variable
  scalars with cursive lowercase letters.
	The epoched \ac{eeg} data with $N$ epochs, $C$ channels, and $S$ samples are
  represented in epoch format as $\{\mat{X}_i\in\mathbb{R}^{C\times S}\}^N_{i=1}$
  or flattened vector format by concatenating all channels for each epoch.
	Flattening results in $\{\mat{x}_i\in\mathbb{R}^{CS}\}^N_{i=1}$ such that
  $\mat{x}_i = \text{vec}(\mat{X}_i)$.
	The real covariance matrix of the epochs in vector format is
  denoted by $\mat{C}$, estimators thereof as $\hat{\mat{C}}$.

	\subsection{Spatiotemporal beamforming}
  \ac{lcmv}-beamforming was initially introduced to \ac{eeg} analysis as a filter for
	source localization~\cite{VanVeen1997} to enhance the signal-to-noise ratio
	(SNR).
	\textcite{VanVliet2015} first applied the spatiotemporal
	\ac{lcmv}-beamformer as a method for the analysis of \acp{erp}.
	The extension to the combined spatiotemporal domain~\cite{VanVliet2015} and the
	data-driven approaches proposed by \textcite{Treder2016} and
	Wittevrongel et al.~\cite{Wittevrongel2016} allow for its application to classification problems.

	For the following analyses, we assume that all \ac{eeg} channels are normalized with zero mean and unit variance without loss of generality.
	Solving \cref{eq:stbf-struct/minimum-variance} under the linear constraint given by
  \cref{eq:stbf-struct/linear-constraint} returns the filter weights $\mat{w}$ defining the spatiotemporal \ac{lcmv}-beamformer.
	\begin{equation}
    \argmin_\mat{w}\mat{w}^\intercal \mat{C}
		\mat{w}^\intercal
		\label{eq:stbf-struct/minimum-variance}
	\end{equation}
	\begin{equation}
		\mat{a}^\intercal\mat{w} = 1
		\label{eq:stbf-struct/linear-constraint}
	\end{equation}
	These weights minimize the variance of the output of the filter while enhancing
	the signal characterized by the constraint.
  $\mat{a} = \text{vec}(\mat{A})$ is the data-driven activation pattern, a template
	of the signal of interest maximizing the difference between two classes of
	epochs, determined as follows:
	\begin{equation}
		\mathbf{a} =
		\frac{1}{|\text{class 1}|}\sum_\text{class 1}\mathbf{x_i} -
		\frac{1}{|\text{class 2}|}\sum_\text{class 2}\mathbf{x_i}
		\label{eq:stbf-struct/ap}
	\end{equation}

	The method of Lagrange multipliers then gives the closed-form solution to the minimization problem posed by
	\cref{eq:stbf-struct/minimum-variance} and \cref{eq:stbf-struct/linear-constraint} as:
	\begin{equation}
		\mat{w} =
    \frac{\mat{C}^{-1}\mat{a}^\intercal}
    {\mat{a}\mat{C}^{-1}\mat{a}^\intercal}
		\label{eq:stbf-struct/closed-form}
	\end{equation}
	The beamformer can be applied to epochs (unseen or not) as:
	\begin{equation}
		y_i = \mathbf{w}\mathbf{x}_i
		\label{eq:stbf-struct/apply-bf}
	\end{equation}
	resulting in a scalar output per epoch.
	The linear constraint in \cref{eq:stbf-struct/linear-constraint} ensures that the
	beamformer maps epochs containing a target response to a score close to one
	and, conversely, epochs not containing a target response to a score close to
	zero.

	\subsection{Covariance matrix regularization}
	While the spatiotemporal beamformer, in theory, achieves optimal separation
	between target and non-target classes, in analogy to linear discriminant
  analysis~\cite{Treder2016}, it does not always perform well on unseen data.
	The main challenge is to find a good estimator for the inverse covariance
  matrix $\mat{C}^{-1}$ since the real underlying covariance matrix generating the data is, in principle, unknown.

	\subsubsection{Empirical covariance estimation}
	\label{sec:stbf-struct/methods/emp-cov}
	Earlier spatiotemporal beamformer studies~\cite{Wittevrongel2016,
		Wittevrongel2016a, Wittevrongel2017, Wittevrongel2017a} use the empirical
	covariance and inverse covariance calculated as follows:
	\begin{equation}
    \hat{\mat{C}}_\text{emp} =
		\frac{1}{N-1}\sum^{N}_{i=1}\mat{x}_i\mat{x}_i^\intercal
		\label{eq:stbf-struct/emp-cov}
	\end{equation}
	\begin{equation}
    \widehat{\mat{C}^{-1}}_\text{emp} = \hat{\mat{C}}_\text{emp}^+
		\label{eq:stbf-struct/emp-inv-cov}
	\end{equation}
	The Moore-Penrose pseudoinverse $^+$, ensures a solution exists when
  $\hat{\mat{C}}_\text{emp}$ is singular.
	\cref{fig:kronlda-covs}a and \cref{fig:kronlda-covs}b respectively show examples of the
	empirical estimators of the covariance and the inverse covariance matrices.
	The empirical estimator suffers from performance and
	stability issues if the number of epochs $N$ used or estimation is not much larger than the number of features $CS$~\cite{Stein1956,Khatri1987}.

	\subsubsection{Shrunk covariance estimation}
	\label{sec:stbf-struct/methods/shrunk-cov}
	The shrinkage covariance estimator creates a better-conditioned inversion matrix problem and generally performs better when applied to unseen data.
	The estimators for the covariance and inverse covariance are given by:
	\begin{equation}
    \hat{\mat{C}}_\alpha =
    (1-\alpha) \hat{\mat{C}}_\text{emp}
    + \alpha\frac{\text{Tr}(\hat{\mat{C}}_\text{emp})}{CS}\mathbb{I}
		\label{eq:shrinkage}
	\end{equation}
	\begin{equation}
    \widehat{\mat{C}^{-1}}_\alpha =
    \hat{\mat{C}}^+_\alpha
		\label{eq:stbf-struct/shrinkage-inv}
	\end{equation}
	with $0<\alpha<1$.
	Analogous to $L_2$ regularization of the beamforming problem,
	shrinkage reduces the ratio between the smallest and largest eigenvalues
	of the covariance matrix by strengthening the diagonal.
	\cref{fig:kronlda-covs}c and \cref{fig:kronlda-covs}d respectively show examples of the
	shrunk estimator of the covariance and the inverse covariance matrices.

	Earlier work~\cite{Libert2021} applied shrinkage regularization to \ac{erp}
	decoding with the spatiotemporal beamformer and showed competitive performance
	compared to other state-of-the-art decoding techniques like stepwise LDA or SVM.
	The abovementioned work chooses the shrinkage coefficient $\alpha$ as a fixed hyperparameter.
	However, its optimal value depends on the number of training epochs, the
	covariance matrix's dimensionality, and the independence and variance of the
	data, which can vary across evaluation settings and per session.
	The optimal value for $\alpha$ can be found with a line search using cross-validation, but this can be a costly procedure.
	Methods exist to estimate an optimal shrinkage value from the data directly.
	Most notable among these are the Ledoit-Wolf procedure~\cite{Ledoit2004},
	Rao-Blackwell Ledoit-Wolf~\cite{Chen2010}, and Oracle Approximating Shrinkage~\cite{Chen2010}.
	A more recent estimation method~\cite{Tong2018} emulates a leave-one-out
	cross-validation (\ac{loocv}) scheme expressed by the data-driven closed-form
	estimate:
	\begin{equation}
		\alpha =
		1-\frac{
      \frac{N}{N-1}\text{Tr}(\hat{\mat{C}}_\text{emp}^2)
      - \frac{2}{CS}\left[\text{Tr}(\hat{\mat{C}}_\text{emp})\right]^2
      + \frac{1}{CS}\text{Tr}(\hat{\mat{C}}_\text{emp}^2)
			- \frac{1}{N(N-1)}\sum_{i=1}^N||\mat{x}_i||_2^4
		}
		{
      \frac{N^2 -2N}{(N-1)^2}\text{Tr}(\hat{\mat{C}}_\text{emp}^2)
      - \frac{2}{CS}\left[\text{Tr}(\hat{\mat{C}}_\text{emp})\right]^2
      + \frac{1}{CS}\text{Tr}(\hat{\mat{C}}_\text{emp}^2)
			+ \frac{1}{N(N-1)^2}\sum_{i=1}^N||\mat{x}_i||_2^4
		}
		\label{eq:loocv}
	\end{equation}

	We opt for the \ac{loocv} shrinkage estimator because it avoids some of the
	assumptions made by~\cite{Ledoit2004} and~\cite{Chen2010} and
	because it generalizes to structured covariance estimation as described in
	\cref{sec:stbf-struct/methods/structured-estimation}.

	\subsubsection{Spatiotemporal beamforming with Kronecker-Toeplitz structured covariance}
	\label{sec:stbf-struct/methods/structured-estimation}
	Exploiting prior knowledge about the spatiotemporal structure of the \ac{eeg} signal leads to a more regularized estimator of the covariance.
	When viewing the example of empirical spatiotemporal \ac{eeg} covariance in
	\cref{fig:kronlda-covs}a, it becomes clear that this matrix consists of a block pattern of repeated, similar matrices.
	Due to the multi-channel nature of the signal, we assume that the covariance of spatiotemporal \ac{eeg} epochs is a Kronecker
	product of two smaller
	matrices~\cite{Munck1992,DeMunck1999,Huizenga2002}, as expressed
	by:
	\begin{equation}
    \hat{\mat{C}}_\text{struct} = \hat{\mat{S}} \otimes \hat{\mat{T}}
		\label{eq:kronecker}
	\end{equation}
	with $\otimes$ the Kronecker product operator.
  $\hat{\mat{S}} \in \mathbb{R}^{C\times C}$ and $\hat{\mat{T}} \in \mathbb{R}^{S\times S}$ respectively correspond to estimators of the spatial and temporal covariance of the data.
	Furthermore, because the temporal covariance of the \ac{eeg}-signal is
	stationary (i.e., it is only dependent on interval length between covarying
	time samples)~\cite{Bijma2003}, it is assumed to have a Toeplitz-matrix structure:
	\begin{equation}
    \hat{\mat{T}}_{i,j} = \hat{\mat{T}}_{i+1,j+1}
		\label{eq:toeplitz}
	\end{equation}
	\Cref{prop:stbf-struct/inverse-kronecker} then leads to
	\cref{eq:stbf-struct/cov-inverse-kronecker} to estimate the inverse
	covariance.

	\begin{property}
    $(\mat{U} \otimes \mat{V})^+ = \mat{U}^+ \otimes \mat{V}^+$ for any non-singular
    matrices $\mat{U}$ and $\mat{V}$~\cite{Langville2004}.
		\label{prop:stbf-struct/inverse-kronecker}
	\end{property}

	\begin{equation}
    \widehat{\mat{C}^{-1}}_\text{struct} = \hat{\mat{S}}^+ \otimes \hat{\mat{T}}^+
		\label{eq:stbf-struct/cov-inverse-kronecker}
	\end{equation}

	Finally, based on \cref{propr:stbf-struct/kron-multiplication},
	\cref{eq:stbf-struct/closed-form} can be reformulated more efficiently as
	\cref{eq:stbf-struct/closed-form-kron}.
	\begin{property}
    $(\mat{U}\otimes \mat{V})\cdot\text{vec}(\mat{W}) =
    \text{vec}(\mat{V}\mat{W}\mat{U}^\intercal)$
    for any matrices $\mat{U}\in\mathbb{R}^{P\times P}$,
    $\mat{V}\in\mathbb{R}^{Q\times Q}$ and $\mat{W}\in\mathbb{R}^{P\times Q}$~\cite{Loan2000}.
		\label{propr:stbf-struct/kron-multiplication}
	\end{property}

	\begin{equation}
		\hat{\mat{w}}_\text{struct} =
    \frac{\hat{\mat{S}}^+\mat{A}^\intercal\hat{\mat{T}}^+}
    {\mat{a}\cdot\text{vec}(\hat{\mat{S}}^+A^\intercal\hat{\mat{T}}^+)}
		\label{eq:stbf-struct/closed-form-kron}
	\end{equation}

	Using \cref{eq:stbf-struct/closed-form-kron} removes the need to calculate the
  full, high dimensional Kronecker product $\hat{\mat{S}}^+\otimes
    \hat{\mat{T}}^+$.
	\Cref{fig:kronlda-covs}e and \cref{fig:kronlda-covs}f respectively show examples of the
	structured covariance and inverse covariance estimators,
	consisting of a spatial Kronecker factor (\cref{fig:kronlda-covs}g and
	\cref{fig:kronlda-covs}h) and a temporal component (\cref{fig:kronlda-covs}i and
	\cref{fig:kronlda-covs}j).

	\begin{figure}
		\includegraphics[width=\linewidth]{figures/stbf_struct/covs.eps}
    \caption[Estimated covariance and inverse covariance.]{Different estimators of the covariance and inverse covariance
			of 100 epochs of data from \textit{Subject 01} for channels
			\textit{Fz}, \textit{Cz}, \textit{Pz}, and \textit{Oz} and time samples between 0.1s and 0.6s.
			Regularized estimators of the inverse covariance exhibit less extreme values and have a sparser structure.
			(\textbf{a,b}) Empirical covariance and inverse covariance matrices.
			(\textbf{c,d}) Shrunk covariance and inverse covariance matrices with $\alpha=0.14$ as
			determined by the closed-form \ac{loocv} method. (\textbf{e,f}) Kronecker-Toeplitz
			structured covariance and inverse covariance matrices.
			(\textbf{g,h}) Spatial Kronecker factor of the Kronecker-Toeplitz structured shrunk estimator and its inverse.
			(\textbf{i,j}) Temporal Kronecker factor of the Kronecker-Toeplitz structured shrunk estimator and its inverse.}
		\label{fig:kronlda-covs}
	\end{figure}

	The Kronecker approach has shown significant performance yields in different linear spatiotemporal \ac{eeg} and MEG
	applications~\cite{DeMunck2002,Huizenga2002,Beltrachini2013,GonzalezNavarro2016,GonzalezNavarro2017}.
	\textcite{Vliet2020} have applied a Kronecker-structured covariance estimator to \ac{erp} classification with linear models in a post-hoc fashion.
	Our work goes further by embedding the Kronecker structure in the
	spatiotemporal beamformer training process, using a data-adaptive shrinkage
	method, and regularizing the covariance further by imposing a Toeplitz
	structure on the temporal covariance.

	\subsubsection{Kronecker-Toeplitz structured covariance estimation}
	\label{sec:stbf-struct/methods/struct-cov}
  The question remains how to estimate $\mat{\hat{S}}$ and $\mat{\hat{T}}$.
	While the Flip-Flop and Non-iterative Flip-Flop
	algorithms~\cite{Lu2005, Werner2008, Wirfaelt2010} can estimate Kronecker or Kronecker-Toeplitz structured covariances, new results show that a fixed point iteration is more efficient~\cite{Wiesel2012a,Wiesel2012}.
	After each iteration, the spatial and temporal covariances matrices are scaled to unit
	variance to ensure the fixed point iteration converges.
	Finally, shrinkage can also be introduced in the Fixed Point Iteration to
	improve stability and achieve more robust
	regularization~\cite{Wiesel2012,Greenewald2014,Beltrachini2013, Breloy2016}.
	The spatial and temporal covariance matrices are shrunk at every fixed-point
	iteration with shrinkage factors $\beta_k$ and $\gamma_k$ before matrix
	inversion in the
	next iteration.

	Combined, this leads to the iterative estimation algorithm described by the
	following equations:
	\begin{subequations}
		\begin{equation}
      \tilde{\mat{S}}_{k+1} =
			\frac{1}{N}
      \sum^N_{i=1}\mat{X}_i^\intercal\hat{\mat{T}}_k^+\mat{X}_i
			\label{eq:stbf-struct/fpi-spatial}
		\end{equation}
		\begin{equation}
      \tilde{\mat{T}}_{k+1} =
			\frac{1}{N}
      \sum^N_{i=1}\mat{X}_i\hat{\mat{S}}_k^+\mat{X}_i^\intercal
			\label{eq:stbf-struct/fpi-temporal}
		\end{equation}
	\end{subequations}
	\begin{subequations}
		\begin{equation}
      \tilde{\mat{S}}_{k+1}^{(\beta)} =
      (1-\beta_{k+1})\tilde{\mat{S}}_{k+1}
      +\beta_{k+1}\frac{\text{Tr}(\tilde{\mat{S}}_{k+1})}{C}\mathbb{I}
			\label{eq:stbf-struct/fpi-spatial-shrunk}
		\end{equation}
		\begin{equation}
      \tilde{\mat{T}}_{k+1}^{(\gamma)} =
      (1-\gamma_{k+1})\tilde{\mat{T}}_{k+1}
      +\gamma_{k+1}\frac{\text{Tr}(\tilde{\mat{T}}_{k+1})}{S}\mathbb{I}
			\label{eq:stbf-struct/fpi-temporal-shrunk}
		\end{equation}
	\end{subequations}
	\begin{subequations}
		\begin{equation}
      \hat{\mat{S}}_{k+1} =
      \frac{C}{\text{Tr}\left[\tilde{\mat{S}}_{k+1}^{(\beta)}\right]}
      \tilde{\mat{S}}_{k+1}^{(\beta)}
			\label{eq:stbf-struct/fpi-spatial-norm}
		\end{equation}
		\begin{equation}
      \hat{\mat{T}}_{k+1} =
      \frac{S}{\text{Tr}\left[\tilde{\mat{T}}_{k+1}^{(\gamma)}\right]}
      \tilde{\mat{T}}_{k+1}^{(\gamma)}
			\label{eq:stbf-struct/fpi-temporal-norm}
		\end{equation}
	\end{subequations}
  $\hat{\mat{S}}_0$ and $\hat{\mat{T}}_0$ can be initialized to any positive definite matrix.
	We choose to use the identity matrices $\mathbb{I}^{C\times C}$ and $\mathbb{I}^{S\times S}$.
  After each iteration, all diagonals of $\hat{\mat{R}}_{k+1}$ are set to their mean
  values to ensure that $\hat{\mat{R}}_{k+1}$ and $\hat{\mat{T}}_{k+1}$ are Toeplitz structured.

	\textcite{Xie2021} show that the \ac{loocv} estimates for the
	optimal values of $\beta_{k+1}$ and $\gamma_{k+1}$ also yield a closed-form
	solution for the Kronecker fixed-point-iteration algorithm:

	\begin{subequations}
		\begin{equation}
			\beta_{k+1} =
			1-
			\frac{
        \frac{N}{N-1}\text{Tr}(\tilde{\hat{S}}_{k+1}^2)
        - \frac{2}{C}\left[\text{Tr}(\tilde{\mat{S}}_{k+1})\right]^2
        + \frac{1}{C}\text{Tr}(\tilde{\mat{S}}_{k+1}^2)
				- \frac{1}{N(N-1)}\sum_{i=1}^N
        \left[\text{Tr}(\mat{X}_i\hat{\mat{T}}_k^+\mat{X}_i^\intercal)^2\right]
			}{
        \frac{N^2-2N}{(N-1)^2}\text{Tr}(\tilde{\mat{S}}_{k+1}^2)
        - \frac{2}{C}\left[\text{Tr}(\tilde{\mat{S}}_{k+1})\right]^2
        + \frac{1}{C}\text{Tr}(\tilde{\mat{S}}_{k+1}^2)
				+ \frac{1}{N(N-1)^2}\sum_{i=1}^N
        \left[\text{Tr}(\mat{X}_i\hat{\mat{T}}_k^+\mat{X}_i^\intercal)^2\right]
			}
			\label{eq:stbf-struct/spatial-shrinkage}
		\end{equation}
		\begin{equation}
			\gamma_{k+1} =
			1-
			\frac{
        \frac{N}{N-1}\text{Tr}(\tilde{\mat{T}}_{k+1}^2)
        - \frac{2}{S}\left[\text{Tr}(\tilde{\mat{T}}_{k+1})\right]^2
				+ \frac{1}{S}\text{Tr}(\tilde{T}_{k+1}^2)
				- \frac{1}{N(N-1)}\sum_{i=1}^N
        \left[\text{Tr}(\mat{X}_i^\intercal\mat{\mat{S}}_k^+\mat{X}_i)^2\right]
			}{
        \frac{N^2-2N}{(N-1)^2}\text{Tr}(\tilde{\mat{T}}_{k+1}^2)
        - \frac{2}{S}\left[\text{Tr}(\tilde{\mat{T}}_{k+1})\right]^2
        + \frac{1}{S}\text{Tr}(\tilde{\mat{T}}_{k+1}^2)
				+ \frac{1}{N(N-1)^2}\sum_{i=1}^N
        \left[\text{Tr}(\mat{X}_i^\intercal\hat{\mat{S}}_k^+\mat{X}_i)^2\right]
			}
			\label{eq:stbf-struct/temporal-shrinkage}
		\end{equation}
	\end{subequations}
	The shrinkage parameters $0<\beta_{k+1}<1$ and $0<\gamma_{k+1}<1$ should be
	re-determined after each iteration.
	The Oracle Approximation Shrinkage method can also be used to determine
	$\beta_{k+1}$ and $\gamma_{k+1}$~\cite{Chen2010,Xie2021} but performs worse for spatiotemporal \ac{eeg} data since not all assumptions are met.

	\subsection{Dataset}
	We use the dataset from~\textcite{Wittevrongel2016}, containing P3 oddball \ac{eeg}
	recordings of 21 healthy subjects since it is a high-quality dataset with a high
	number (32) of electrodes and concurrently recorded EOG responses for ocular artifact rejection.
	Nine targets were arranged on a monitor before the subject during an
	experimental session.
	The subject was asked to pay attention to a cued target for a block
	of stimulations.
	The stimulations in a block are organized in 15 separate subsequent trials.
	A trial is defined as 9 stimulations in which each target is flashed
	precisely once per trial.
	Each target was cued four times, resulting in a dataset consisting of 36 blocks
	(4860 stimulations) per subject.
	Each stimulation will correspond to a single epoch in the preprocessed dataset.
	See~\textcite{Wittevrongel2016} for a complete description of the dataset and the recording procedure.

	\subsection{Software and preprocessing}
	Data processing and classifier analysis were performed in Python using
	Scikit-Learn (version 1.0.1)~\cite{Pedregosa2011} and SciPy (version
	1.7.1)~\cite{Virtanen2020}.
	The preprocessing pipeline was implemented using the MNE-Python toolbox
	(version 0.24.0)~\cite{Gramfort2013}.
	The dataset was converted to BIDS-\ac{eeg} format~\cite{Pernet2019} and managed and
	loaded with MNE-BIDS (version 0.9)~\cite{Appelhoff2019}.
	The Riemannian classifier from \cref{sec:riemannian} was implemented using
	pyRiemann (version 0.2.7).
	Statistical tests were performed in R (version 4.1.2).

	The \ac{eeg} recorded at 2048Hz was re-referenced off-line to the average of the mastoids.
	The reference electrodes were dropped from the analysis.
	Data were subsequently filtered between 0.5Hz and 16Hz using forward-backward
	filtering with a fourth-order Butterworth IIR filter.
	The \ac{eeg} signal was corrected for ocular artifacts using Independent Component
	Analysis (ICA) by rejecting components that correlated with the bipolar EOG channels vEOG and hEOG, according to adaptive Z-score thresholding.
	Finally, epochs were cut from 0.1s to 0.6s after stimulus onset.
	No baseline correction was performed since this affects the temporal covariance
	of the data, violating the Toeplitz structure assumption~\cite{Bijma2003}.

	\subsection{Classification}
	\subsubsection{Cross-validation scheme per subject}
	We use a variation of grouped fold cross-validation per subject to evaluate the classifiers.
	We apply 4-fold cross-validation by splitting the blocks of each subject into
	four continuous folds.
	Unlike regular cross-validation, we only use a single fold to train the
	classifiers while using the other three folds for validation.
	This scheme results in a training set of 9 blocks of 135 epochs each.
	We chose this approach since we are primarily interested in the performance of the classifiers in the case of low data availability.
	The classification task is to determine the cued target for each block.
	The fraction of correctly predicted cues provides the accuracy of a classifier.
	Data from all trials are used in the training fold, while classifier validation
	is performed multiple times per fold, each time using an increasing amount of
	trials (i.e., using the first trial, using the first two trials, etc. until all 15 trials
	are used).
	For each of the 9 stimulated targets, the averages over the corresponding epochs across
	the utilized trials are used to predict the cued target in that block.
	The target with the maximal classifier score was then chosen as the predicted
	cued target.
	Before training the classifiers, a Z-score normalization transformation was
	developed on the training data to scale all \ac{eeg} channels to unit variance.
	This transformation was then applied to the validation data.

  \subsubsection{\Acl{stbf} classifier}
	Before calculating the \ac{stbf}, the signal was downsampled to
	32Hz or twice the low-pass frequency 16Hz, resulting in 17 time samples
	between 0.1 and 0.6s. According to the Nyquist Theorem, more samples would not
	contain more information hence the minimum temporal resolution is chosen to reduce
	the dimensionality of the covariance and improve its covariance.
	The activation pattern is the difference between the averages of epochs in response to cued targets and the averages of those in response to non-cued targets.
	We constructed three variations of the spatiotemporal beamformer:
	\ac{stbf} with empirical covariance estimation (\textsc{stbf-emp}) as in
	\cref{sec:stbf-struct/methods/emp-cov}, \ac{stbf} with
	\ac{loocv}-shrunk covariance estimation (\textsc{stbf-shrunk}) as in
	\cref{sec:stbf-struct/methods/shrunk-cov}, and \ac{stbf} with
	Kronecker-Toeplitz structured covariance estimation (\textsc{stbf-struct}) with \ac{loocv} shrinkage for
	the Kronecker factors as in \cref{sec:stbf-struct/methods/struct-cov}.

	\subsubsection{Riemannian geometry classifier}
	\label{sec:riemannian}
	We opted for a Riemannian
	geometry-based classifier to compare our results.
	The Riemannian model (\textsc{xdawn+rg}) uses the XDAWN spatial filter combined
	with Riemannian geometry in tangent space as implemented by Barachant et
	al.~\cite{Barachant2014a}.
	This classifier uses four XDAWN spatial filters and each epoch's empirical spatial covariance matrix.
	The target with the maximum score is the prediction of the cued target.
	\textsc{xdawn+rg} was trained and validated without downsampling using epochs
	at the original sample rate of 2048Hz.

	\section{Results}
	\subsection{Minimum required fixed-point iterations}
	The fixed point iteration algorithm described
	in
  \crefrange{eq:stbf-struct/fpi-spatial}{eq:stbf-struct/fpi-temporal-norm}
  estimates the Kronecker-Toeplitz structured covariance for the
	\textsc{stbf-struct} classifier.
	Fixed-point iteration is an iterative procedure starting from (in our case)
	non-informed initial guesses for the spatial and temporal covariance matrices.
	As a stopping criterion, one could impose a threshold on the difference in
	outcome of successive steps, e.g., based on the covariance norm or the
	classifier accuracy.
	However, few iterations or even just one~\cite{Castaneda2014} suffice to achieve satisfactory performance in practice.

	\cref{fig:iterations} confirms these results for the \textsc{stbf-struct} classifier.
	Using more than one fixed-point iteration does not significantly improve the
	accuracy across the amounts of training data and the number of trials
	used for evaluation.
	Hence, only one iteration is used for the \textsc{stbf-struct} classifier, leading to a drastic speed-up of
	the training process.

  \begin{figure}
		\includegraphics[width=\linewidth]{figures/stbf_struct/fpi.eps}
    \caption[Average cross-validated \textsc{stbf-struct} accuracy]{%
      Average cross-validated \textsc{stbf-struct} accuracy using
			one trial per block over all 21 subjects
			relative to the number of iterations used to estimate the Kronecker-Toeplitz structured shrunk
			covariance. Error bars represent the first and third quartiles. The
			accuracy does not improve when using more than one iteration.
			(\textbf{a}) Results for 1, 2, and 5 trials using only the first block in each
			training fold for training. (\textbf{b}) Results
			for 1, 2, and 5 trials using
			all nine training blocks in the training folds.
		}
		\label{fig:iterations}
	\end{figure}

	\subsection{Classifier accuracy for limited training data}
	It is of interest to keep the calibration time before \ac{bci}
	operation as short as possible.
	We mimic this problem by training the classifier with as few training epochs as possible.
	We evaluate the performance of all classifiers for different levels of
	available training data and apply the cross-validation procedure nine times (the number of blocks in the training fold) for all subjects, keeping the
	corresponding number of blocks in the training folds and dropping the rest.
	\Cref{fig:accuracy} and \cref{fig:stbf-struct/accuracy-ap} show each classifier's
	accuracy relative to the data availability.
	We statistically compare the two newly proposed classifiers,
	\textsc{stbf-struct} and \textsc{stbf-shrunk}, for different levels of training
	data availability using a one-sided paired Wilcoxon rank-sum test with Holm correction for the multiple pairwise comparisons between classifiers.
	We performed this analysis three times: by only using the first trial of a
	block, by averaging epochs across the first two trials of a block and across
	the first five trials of a block.
	Results validated on one trial are reported in \cref{tab:stbf-struct/p-values-1}, 2-trial results
	in \cref{tab:stbf-struct/p-values-2}, and 5-trial results in \cref{tab:stbf-struct/p-values-5}.

  \begin{figure}
		\includegraphics[width=.66\linewidth]{figures/stbf_struct/accuracy.eps}
    \caption[Clasifier accuracy in function of available training data.]{%
      Accuracy of the different classifiers for all 21 subjects relative to the
			number of blocks available for training. One block consists of 135
			epochs and corresponds to 27 seconds of stimulation. Accuracies
			are shown for the evaluation settings averaging over 1, 2, and
			3 trials of testing stimuli.
			\cref{fig:stbf-struct/accuracy-ap} contains results for all numbers of trials.
			While \textsc{stbf-emp} is unstable when little training data
			are available,
			regularization of the covariance matrix (\textsc{stbf-shrunk} and
			\textsc{stbf-struct}) drastically improves performance.}
		\label{fig:accuracy}
	\end{figure}

  \fullpagefig{%
		\includegraphics[width=\textwidth]{figures/stbf_struct/accuracy_app.eps}
  }{%
    \caption[Accuracy averaging over different numbers of trials.]{%
      Accuracy of the different classifiers for all 21 subjects relative to the
		  number of blocks available for training. One block consists of 135
		  epochs and corresponds to 27 seconds of stimulation. Accuracies
		  are shown for the evaluation settings averaging over different
	    numbers of trials, ranging from 1 to 15.
    }
    \label{fig:stbf-struct/accuracy-ap}
  }

  \begin{table}[p]
		\centering
    \makebox[\textwidth][c]{%
		\input{chapters/stbf_struct_tests_1.tex}
  }
    \caption[Statistical significance of differences in classifier performance (1 repetition).]{%
      Statistical significance of differences in classifier performance.
      $p$-values calculated by one-sided paired Wilcoxon rank-sum test with
			Holm correction using one testing trial for different classifiers
			and levels of data availability. $p$-values $<0.05$ are considered significant
			and marked in grey.}
		\label{tab:stbf-struct/p-values-1}
    \bigskip

		\centering
    \makebox[\textwidth][c]{%
		\input{chapters/stbf_struct_tests_2.tex}
    }
		\caption[Statistical significance of differences in classifier performance (2 repetitions).]{%
      $p$-values as in \cref{tab:stbf-struct/p-values-1} averaging over two testing trials.}
		\label{tab:stbf-struct/p-values-2}
    \bigskip

		\centering
    \makebox[\textwidth][c]{%
		\input{chapters/stbf_struct_tests_3.tex}
    }
    \caption[Statistical significance of differences in classifier performance (5 repetitions).]{%
      $p$-values as in \cref{tab:stbf-struct/p-values-1} averaging over five testing trials.}
		\label{tab:stbf-struct/p-values-5}
	\end{table}
	\unskip

	The tables show that \textsc{stbf-struct} has a significant advantage over
	\textsc{stbf-shrunk} when the number of training blocks is low.
	This effect is present for 1-, 2- and 5-trial evaluation.
	This advantage decreases (the $p$-value increases) when
	adding more training blocks.
	Both \textsc{stbf-struct} and \textsc{stbf-shrunk} perform significantly better
	than \textsc{stbf-emp} for all evaluated settings.
	Compared to \textsc{xdawn+rg}, \textsc{stbf-struct} also has significantly
	higher accuracy in almost all evaluated settings, except when using only one training block.
	\textsc{stbf-shrunk} does not outperform \textsc{xdawn+rg} when training data is low but gains a significant advantage
	when using more training data.

	\subsection{Classifier training time}
	In order to evaluate the training time of the investigated classifiers, the
	cross-validation scheme is run four times for each subject, each time with an
	increasing number of \ac{eeg} channels retained in the analysis, to explore the scalability of each classifier for analyses with higher spatial resolutions.
	The temporal resolutions were not varied, but we expect that increasing the
	temporal resolution has a similar effect on training time since the
	training times for the \textsc{stbf}-based as evidenced by the complexity
	calculations in \cref{sec:stbf-struct/discussion/param-complex}.
	\cref{fig:stbf-struct/training-time} shows the measured training times.
	These results were obtained using a laptop with an Intel® Core™ i7-8750H CPU and 16GB of RAM.

	\begin{figure}
		\includegraphics[width=.66\linewidth]{figures/stbf_struct/training_time.eps}
    \caption[Classifier training time.]{Median fold training time for different classifiers at different spatial
			resolution levels evaluated over all training folds for all subjects.
			Error bars represent standard deviation. The training time of \textsc{stbf-shrunk} increases more
			steeply with resolution compared to \textsc{stbf-struct}.
			All \textsc{stbf} classifiers can be trained significantly faster than
			\textsc{xdawn+rg}.}
		\label{fig:stbf-struct/training-time}
	\end{figure}

	\cref{fig:stbf-struct/training-time} shows that the training time of
	\textsc{stbf-struct} increases less steeply than that of \textsc{stbf-shrunk}
	and \textsc{stbf-emp}. The training time of all three \ac{stbf}-based classifiers is
	much lower than that of \textsc{xdawn+rg}, which appears nearly constant when using
	4, 8, 16, or 32 channels.

	\section{Discussion}

	\subsection{Classification accuracy}
	As evidenced by \cref{fig:accuracy} and Tables \ref{tab:stbf-struct/p-values-1}-\ref{tab:stbf-struct/p-values-5}, the regularized classifiers \textsc{stbf-shrunk}
	and \textsc{stbf-struct} significantly improve the classification accuracy
	compared to the original \textsc{stbf-emp} for all numbers of training blocks
	indicated.
	We believe there are three reasons for this.
	First and foremost, the empirical covariance matrix in \textsc{stbf-emp} becomes
	ill-conditioned when the number of available training epochs is smaller than
	the number of features ($N<CS$), rendering its inversion with the
	Moore-Penrose pseudoinverse unstable.
	This is the case \textsc{stbf-emp} when $N=CS=32*17=544$, after which the
	accuracy of \textsc{stbf-emp} starts to increase.
	This effect is visible in \cref{fig:accuracy}, where the accuracy starts
	increasing when using more than four training blocks, amounting to 540 epochs.
	The noticeable dip in accuracy when using around 540 epochs can be explained by
	numerical effects in the pseudoinverse for very small
	eigenvalues~\cite{Blankertz2011, Raudys1998, Schaefer2004,
		Kraemer2009}.
	Regularization of the covariance matrix with shrinkage ensures that the
	covariance matrix is non-singular and better conditioned so it can stably be inverted.
	Second, covariance regularization introduces a trade-off between variance and bias of the model~\cite{Ledoit2004}.
	Better performance on unseen data can be achieved when some model variance is
	traded for extra bias.
	Regularization reduces extreme values present, as shown in
	\cref{fig:kronlda-covs}, resulting in a classifier with
	better generalization.
	Third, the true spatiotemporal covariance matrix may vary throughout \ac{bci}
	sessions, e.g., due to movement of the \ac{eeg}-cap, changing impedances of
	electrodes, subject fatigue, the introduction of new spatiotemporal noise
	sources, and other possible confounds.
	A regularized covariance matrix should better account for changes in true covariance.
	Note that the \ac{loocv} method in principle assumes that the covariances of
	the training data and unseen data are the same.
	Because the covariance might have changed for unseen data, the shrinkage
	estimate obtained with \ac{loocv} is probably still an
	underestimation of the optimal -- but unknown -- shrinkage coefficient that
	would yield the best classification accuracy for the unseen data.

	Another observation is the significantly better accuracy score of
	\textsc{stbf-struct} over \textsc{stbf-shrunk} when the amount of available training data is small.
	This property is an attractive advantage in a \ac{bci} setting since it is desirable to keep the calibration (training) phase as short as possible without losing accuracy.
	The accuracy advantage of the structured estimator is a consequence of the
	Kronecker-Toeplitz covariance structure, which is informative for the
	underlying process generating the epochs, if it is assumed that the \ac{eeg} signal
	is a linear combination of stationary activity generated by random dipoles in
	the brain with added noise~\cite{Munck1992, DeMunck2002, GonzalezNavarro2017}.
	Hence, \textsc{stbf-struct} can utilize this prior information to better estimate the inverse
	covariance.
	The increase in accuracy for small training set sizes can also be explained by the smaller number of parameters necessary to estimate the inverse covariance (see \cref{sec:stbf-struct/discussion/param-complex}), increasing the stability of matrix inversions.

	When compared to the state-of-the-art \textsc{xdawn+rg} classifier, we conclude
	that \textsc{stbf-struct} reaches similar accuracy when using only one block of
	training data.
	The authors suspect this is due to both
	classifiers having insufficient training information to reach
	satisfactory classification accuracy.
	When more data are available, \textsc{stbf-struct} reaches significantly better accuracies.
	Combined with the benefits laid out in \cref{sec:stbf-struct/discussion/param-complex}, this
  makes it an attractive option for \ac{erp} classification.
	\textsc{stbf-shrunk} does not show decisive accuracy improvements over
	\textsc{xdawn+rg} using a few training blocks, but this improves as the training data increases.

	\subsection{Time and memory complexity}
	\label{sec:stbf-struct/discussion/param-complex}
	As mentioned above, inverting the full $CS \times CS$ dimensional covariance
	matrix to construct \textsc{stbf-emp} and \textsc{stbf-shrunk} can be costly
	and unstable, in particular in high-resolution settings with many \ac{eeg} channels or time samples.
	Constructing the full covariance and inverse covariance matrices also requires a considerable amount of memory.
	The structured covariance estimator of \textsc{stbf-struct} has two advantages here.

	First, because of \cref{prop:stbf-struct/inverse-kronecker} and
	\cref{propr:stbf-struct/kron-multiplication} there is no need to calculate or keep in memory the full $cs\times cs$
	symmetric covariance and inverse covariance matrices for \textsc{stbf-struct}; they can instead be replaced by two smaller symmetric matrices respectively of dimensions $c\times c$ and $s\times s$.
	Furthermore, since the temporal component of the Kronecker product is
	Toeplitz-structured, it only requires $s$ parameters to
	estimate.
	While the inverse covariance of \textsc{stbf-emp} and \textsc{stbf-shrunk} is
	defined by $\frac{CS(CS+1)}{2}=\frac{32\cdot17(32\cdot17+1)}{2}=\num{122128}$
	parameters accounting for the symmetric nature of
	covariance, the structured estimator only requires $\frac{C(C+1)}{2} + S =
		\frac{32(32+1)}{2} + 17=545$ unique parameters.
	This reduction in parameters to estimate reduces memory usage and contributes to the regularization effect for low data availability settings.
	The inverse covariances of \textsc{stbf-emp} and
	\textsc{stbf-struct}, represented as $32*17\times 32*17$ symmetric matrices of
	single-precision real floating point numbers for weight calculation,
	use 9.03MiB of memory.
	The $32\times 32$ and $17\times 17$ matrices of \textsc{stbf-struct} only
	require 5.12KiB.

	Second, structured estimation has better time complexity.
	Covariance estimation and inversion occupy the largest part of the \ac{stbf} training time.
	For \textsc{stbf-emp} and \textsc{stbf-shrunk}, the time complexity of this process is $\mathcal{O}(NC^2S^2+C^3S^3)$.
	Thanks to Property~\ref{prop:stbf-struct/inverse-kronecker}, the complexity can be reduced to
	$\mathcal{O}(NS^2S^2+C^3+S^3)$ for the structured estimator of \textsc{stbf-struct}.
	The results presented in \cref{fig:stbf-struct/training-time} confirm these
	calculations.
	It can be observed that the training time of \textsc{stbf-struct} stays low compared to \textsc{stbf-emp} and \textsc{stbf-shrunk} when dimensionality increases.

	The results shown in \cref{fig:stbf-struct/training-time} also confirm that the
	\ac{stbf}-based estimators are very fast to train compared to the
	state-of-the-art estimator \textsc{xdawn+rg}, which confirms the results in~\cite{Wittevrongel2016}.
	Since the training times of all \ac{stbf}-based classifiers are already in
	the order of tenths of seconds, the question arises whether the
	improvements achieved by using the structured estimator would be relevant in
	practice.
	However, the authors believe that these results could significantly impact some
	use cases of the spatiotemporal beamformer, like high spatial or temporal resolution \ac{erp} analyses.
	One example is single-trial \ac{erp} analysis with a high-temporal
	resolution to extract \ac{erp} time features.
	Such higher-resolution analyses can later be incorporated into an \ac{erp}
	classification framework.
	In addition, the speed-up provided by structured estimation yields a faster
	off-line evaluation of the \ac{stbf} \ac{erp} classifier, where often multiple cross-validation folds, subjects, and hyperparameter settings need to be explored, which can quickly increase runtime.
	Improvements in computation speed and memory usage can remove the need for dedicated computation hardware and enable running group analyses on a personal computer.

	%	\subsection{Interpreting the weights}
	%	\label{sec:interpretability}
	%	The weight matrix of the \ac{stbf} determines how each
	%	spatiotemporal feature of a given epoch should contribute to enhancing the SNR
	%	of the discriminating signal in the classification
	%	task.
	%	Alternatively, the activation pattern can be regarded as a forward \ac{eeg} model of
	%	the activity generating the discriminating signal and the weights as a
	%	backward model~\cite{Blankertz2011,Haufe2014}.
	%	Regularization enables a researcher to interpret better the distribution of the weight over space and time after reshaping the weight vector $\mathbf{w}$ to its spatiotemporal matrix equivalent $W$ such that $\text{vec}(W) = \mathbf{w}$.
	%	\cref{fig:interpret_weights} compares the weights calculated in
	%	\textsc{stbf-emp} and \textsc{stbf-shrunk} with the weights from
	%	\textsc{stbf-struct}.
	%
	%	\begin{figure}
	%		%\includegraphics[width=\linewidth]{figures/weights.eps}
	%		\caption{Spatiotemporal beamformer weights calculated using four
	%			blocks of data (of 1215 epochs) from \textit{Subject 01} from
	%			0.2s before to 1.0s after stimulus onset.
	%			Regularized weights show an interpretable sparse pattern,
	%			while the empirical weights appear noisier.
	%			(\textbf{a}) Spatiotemporal activation pattern with spatial and temporal global field
	%			power.
	%			(\textbf{b}) \textsc{stbf-struct} weights with spatial and temporal average of
	%			absolute values.
	%			(\textbf{c}) \textsc{stbf-shrunk} weights. The shrinkage factor $\alpha=0.05$ was
	%			determined with the closed-form \ac{loocv}-method.
	%			(\textbf{d}) \textsc{stbf-emp} weights.}
	%		\label{fig:interpret_weights}
	%	\end{figure}
	%
	%	Since the linear filter's noise suppression and signal amplification functions are deeply entangled, it is not necessarily true that features with a
	%	high filter weight directly correlate to features containing discriminatory
	%	information~\cite{Haufe2014}.
	%	However, it still is possible to interpret the weights in terms of which
	%	features contribute most to the classification process, be it through noise
	%	suppression, signal amplification, or -- most likely -- a combination of both.
	%	The weights obtained by \textsc{stbf-emp} look randomly distributed over space
	%	and time; the regularized estimator used by \textsc{stbf-shrunk} and
	%	\textsc{stbf-struct} reveal a more interpretable weight distribution.
	%	The \textsc{stbf-shrunk} weights show a sparse spatial distribution while
	%	the \textsc{stbf-struct} weights show a sparse distribution in both space and in
	%	time.
	%
	%	As expected, \cref{fig:interpret_weights}b and d exhibit weight around
	%	the central and parietal regions, where the P3 \ac{erp} component is present.
	%	Especially the spatial weights of \textsc{stbf-shrunk} in
	%	\cref{fig:interpret_weights}d correspond to the spatial activation pattern
	%	in \cref{fig:interpret_weights}a.
	%	This is not unsurprising, since shrinkage transforms the covariance matrix closer to the
	%	identity matrix and assuming identity covariance in \cref{eq:stbf-struct/closed-form} yields weights
	%	identical to the activation pattern (up to a scaling factor).
	%	Additionaly, \cref{fig:interpret_weights}b shows that weights in the baseline interval and after 0.6s, which should
	%	contain no response information, are close to zero for the structured estimator.
	%	Meanwhile, these weights are high in the occipital region between 0.1s and 0.2s,
	%	containing early visual components with relatively low SNR.
	%	This high weight for the early visual components confirms the results from Treder \& Blankertz~\cite{Treder2010}
	%	that state that, in addition to the P3, the early N1 and P2 \ac{erp} components
	%	are also modulated by oddball attention and contain discriminatory information between
	%	attended and non-attended stimuli.
	%
	%	Using an interpretable classification model has many advantages.
	%	For instance, one can use the weight matrix determine relevant time samples
	%	and \ac{eeg} channels for per-subject feature selection to refine the model further .
	%	The number of channels is also an important cost factor in practical \ac{bci}
	%	applications.
	%	Determining which channels do not contribute to the classification accuracy
	%	helps reduce the number of required electrodes.
	%	Spatially clustered weights indicate that some electrodes are not used by the
	%	classifier and can be discarded accordingly with no substantial accuracy
	%	reduction.
	%	As another example, information about the timing and spatial distribution of
	%	the discriminatory information in the response can be extracted from the
	%	weights
	%	and linked neurophysiological hypotheses.


	\section{Conclusion}
	While it is possible to regularize the spatiotemporal \ac{lcmv} beamformer
	classifier for \ac{erp} detection with other methods such as by employing feature selection,
	by adding regularizing penalties to the cost
	function beamforming problem, or by crafting a cleaner activation pattern, our work focused on
	estimation methods for the spatiotemporal covariance.
	We introduced a covariance estimator using adaptive shrinkage and an
	estimator exploiting prior knowledge about the spatiotemporal nature of the \ac{eeg}
	signal.
	We compared these estimators with the original spatiotemporal
	beamformer and a state-of-the-art method in an off-line P3 detection task.
	Our results show that the structured estimator performs better when training data are sparsely available and that it can be computed faster and with substantially less memory usage.
	Since these algorithms are not paradigm-specific,  the conclusions can be generalized to
	other \ac{erp}-based \ac{bci} settings.

	Future work should focus on introducing more robust regularization strategies using prior knowledge, such as shrinking the spatial covariance to a population mean or a priorly known matrix based on sensor geometry or characterizing the temporal covariance as a wavelet or autoregressive model.
	More accurate results could be obtained by expressing the covariance as the sum of multiple Kronecker products to account for spatial variation in temporal
	covariance.
	It could also be interesting to explore the impact of covariance regularization on transfer learning of the \ac{stbf} between subjects to alleviate calibration entirely.
	Finally, it could be insightful to evaluate the proposed algorithms in a
	real-world on-line \ac{bci} setting.


%\begin{equation}
%	\mat{C} = \mat{S}\otimes\mat{T}
%\end{equation}
%Tapering, Toeplitz and shrinkage
%\subsection{The Kronecker sum covariance model}
%\begin{equation}
%	\mat{C} = \sum_k^{CS}\mat{S}\otimes\mat{T}
%\end{equation}
